{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6359037a-6dfc-46a4-8704-6cd61726b28d",
   "metadata": {},
   "source": [
    "# THIS FOLLOWING JSON WORKS FOR GENERATING AN EXCEL FILE THAT WORKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f546fa-08d1-4726-adc4-c0f8e9f05b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with JSON segmentation data has been successfully created and saved as C:\\Users\\E106467\\Documents\\Json Mathilde\\Segmentation_Output_05.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the TLD data with multi-level headers\n",
    "tld_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\filtered_Tld_B2B_modified (1).xlsx\", header=[0, 1])\n",
    "tld_data.columns = [' '.join(col).strip() for col in tld_data.columns.values]\n",
    "\n",
    "# Load the CVL file without dropping any rows\n",
    "cvl_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\CVL_B2B Benefit and Business Key.xlsx\")\n",
    "\n",
    "# Create mappings with NaN values handled gracefully\n",
    "business_need_mapping = cvl_data.set_index('BusinessNeed_Key')['Business Need'].to_dict()\n",
    "benefit_id_mapping = cvl_data.set_index('Benefit in your country')['Benefits_Key'].to_dict()\n",
    "\n",
    "# Initialize list to store data for Excel output\n",
    "excel_data = []\n",
    "\n",
    "# Process each row in the TLD data\n",
    "for _, row in tld_data.iterrows():\n",
    "    product_global_id = row.get(\"Unnamed: 1_level_0 ProductGlobalID\", \"\").strip()\n",
    "    product_entity_sys_id = str(row.get(\"Unnamed: 0_level_0 sys_id\", \"\")).strip()\n",
    "    \n",
    "    if not product_global_id or not product_entity_sys_id:\n",
    "        print(f\"Skipping row due to missing ProductGlobalID or sys_id: {row}\")\n",
    "        continue\n",
    "\n",
    "    # Retrieve existing JSON from \"Segmentation json\" if present, otherwise create a new one\n",
    "    existing_json_str = row.get(\"Unnamed: 3_level_0 Segmentation json\", \"{}\").strip()\n",
    "    try:\n",
    "        segmentation_json = json.loads(existing_json_str) if existing_json_str else {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Malformed JSON for ProductGlobalId {product_global_id}. Attempting to repair.\")\n",
    "        # Attempt minimal repair\n",
    "        if not existing_json_str.startswith(\"{\"):\n",
    "            existing_json_str = \"{\" + existing_json_str\n",
    "        if not existing_json_str.endswith(\"}\"):\n",
    "            existing_json_str += \"}\"\n",
    "        try:\n",
    "            segmentation_json = json.loads(existing_json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to repair JSON for ProductGlobalId {product_global_id}. Using default structure.\")\n",
    "            segmentation_json = {\n",
    "                \"ProductGlobalId\": product_global_id,\n",
    "                \"ProductEntitySysId\": product_entity_sys_id,\n",
    "                \"MarketModels\": []\n",
    "            }\n",
    "\n",
    "    # Define the French market model with the data from TLD and CVL files\n",
    "    fr_market_model = {\n",
    "        \"LocaleId\": \"fr-FR\",\n",
    "        \"LocaleName\": \"French (France)\",\n",
    "        \"BusinessNeeds\": []\n",
    "    }\n",
    "\n",
    "    # Process each BusinessNeed\n",
    "    for business_need_id, business_need_name in business_need_mapping.items():\n",
    "        if pd.isna(business_need_id) or pd.isna(business_need_name):\n",
    "            continue  # Skip if either key or name is missing\n",
    "\n",
    "        business_need_entry = {\n",
    "            \"BusinessNeedId\": str(int(business_need_id)),\n",
    "            \"Benefit\": {\n",
    "                \"BenefitId\": \"\",\n",
    "                \"DisplayOrder\": \"\",\n",
    "                \"ReasonToBelieve\": \"\",\n",
    "                \"TechnicalProof\": \"\",\n",
    "                \"LegalNotice\": \"\",\n",
    "                \"ImageUrl\": \"\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Retrieve the BenefitId and other attributes based on column names with suffixes\n",
    "        benefit_name = row.get(f\"{business_need_name} Benefit in your country\", \"\")\n",
    "        if benefit_name in benefit_id_mapping:\n",
    "            benefit_id = benefit_id_mapping[benefit_name]\n",
    "            business_need_entry[\"Benefit\"][\"BenefitId\"] = benefit_id\n",
    "\n",
    "        # Define the column names with suffixes to get specific attributes\n",
    "        display_order_col = f\"{business_need_name} Sort order in your country (from 1 to 9)\"\n",
    "        reason_col = f\"{business_need_name} Reason to believe in your language\"\n",
    "        proof_col = f\"{business_need_name} Technical proof in your language\"\n",
    "        legal_notice_col = f\"{business_need_name} Legal notice in your language\"\n",
    "        \n",
    "        # Retrieve each attribute for the business need\n",
    "        business_need_entry[\"Benefit\"][\"DisplayOrder\"] = row.get(display_order_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"ReasonToBelieve\"] = row.get(reason_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"TechnicalProof\"] = row.get(proof_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"LegalNotice\"] = row.get(legal_notice_col, \"\")\n",
    "\n",
    "        # Append the business need entry to the French market model\n",
    "        fr_market_model[\"BusinessNeeds\"].append(business_need_entry)\n",
    "\n",
    "    # Update or add the French market model in the segmentation JSON without removing other locales\n",
    "    found_fr_market = False\n",
    "    for market_model in segmentation_json.get(\"MarketModels\", []):\n",
    "        if market_model[\"LocaleId\"] == \"fr-FR\":\n",
    "            market_model.update(fr_market_model)\n",
    "            found_fr_market = True\n",
    "            break\n",
    "\n",
    "    if not found_fr_market:\n",
    "        segmentation_json.setdefault(\"MarketModels\", []).append(fr_market_model)\n",
    "\n",
    "    # Convert updated JSON to string and prepare for Excel output with \"ProductSegmentationJson\" as the column name\n",
    "    segmentation_json_str = json.dumps(segmentation_json, ensure_ascii=False)\n",
    "    excel_data.append({\n",
    "        \"ProductSegmentationJson\": segmentation_json_str,\n",
    "        \"sys_id\": product_entity_sys_id,\n",
    "        \"ProductGlobalId\": product_global_id\n",
    "    })\n",
    "\n",
    "# Write updated data to Excel\n",
    "df_output = pd.DataFrame(excel_data)\n",
    "output_excel_path = \"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\Segmentation_Output_05.xlsx\"\n",
    "df_output.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"The Excel file with JSON segmentation data has been successfully created and saved as {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae4be21-7104-48bb-9342-8a1e2334dcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel file with JSON segmentation data has been successfully created and saved as C:\\Users\\E106467\\Documents\\Json Mathilde\\Segmentation_Output_006.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Specify the LocaleId and LocaleName for the target country\n",
    "locale_id = \"bg-BG\"  # Replace with the desired LocaleId (e.g., \"bg-BG\" for Bulgarian)\n",
    "locale_name = \"Bulgarian (Bulgaria)\"  # Replace with the corresponding LocaleName\n",
    "\n",
    "# Load the TLD data with multi-level headers\n",
    "tld_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\filtered_Tld_B2B_modified (1).xlsx\", header=[0, 1])\n",
    "tld_data.columns = [' '.join(col).strip() for col in tld_data.columns.values]\n",
    "\n",
    "# Load the CVL file without dropping any rows\n",
    "cvl_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\CVL_B2B Benefit and Business Key.xlsx\")\n",
    "\n",
    "# Create mappings with NaN values handled gracefully\n",
    "business_need_mapping = cvl_data.set_index('BusinessNeed_Key')['Business Need'].to_dict()\n",
    "benefit_id_mapping = cvl_data.set_index('Benefit in your country')['Benefits_Key'].to_dict()\n",
    "\n",
    "# Initialize list to store data for Excel output\n",
    "excel_data = []\n",
    "\n",
    "# Process each row in the TLD data\n",
    "for _, row in tld_data.iterrows():\n",
    "    product_global_id = row.get(\"Unnamed: 1_level_0 ProductGlobalID\", \"\").strip()\n",
    "    product_entity_sys_id = str(row.get(\"Unnamed: 0_level_0 sys_id\", \"\")).strip()\n",
    "    \n",
    "    if not product_global_id or not product_entity_sys_id:\n",
    "        print(f\"Skipping row due to missing ProductGlobalID or sys_id: {row}\")\n",
    "        continue\n",
    "\n",
    "    # Retrieve existing JSON from \"Segmentation json\" if present, otherwise create a new one\n",
    "    existing_json_str = row.get(\"Unnamed: 3_level_0 Segmentation json\", \"{}\").strip()\n",
    "    try:\n",
    "        segmentation_json = json.loads(existing_json_str) if existing_json_str else {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Malformed JSON for ProductGlobalId {product_global_id}. Attempting to repair.\")\n",
    "        # Attempt minimal repair\n",
    "        if not existing_json_str.startswith(\"{\"):\n",
    "            existing_json_str = \"{\" + existing_json_str\n",
    "        if not existing_json_str.endswith(\"}\"):\n",
    "            existing_json_str += \"}\"\n",
    "        try:\n",
    "            segmentation_json = json.loads(existing_json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to repair JSON for ProductGlobalId {product_global_id}. Using default structure.\")\n",
    "            segmentation_json = {\n",
    "                \"ProductGlobalId\": product_global_id,\n",
    "                \"ProductEntitySysId\": product_entity_sys_id,\n",
    "                \"MarketModels\": []\n",
    "            }\n",
    "\n",
    "    # Define the market model for the specified locale\n",
    "    target_market_model = {\n",
    "        \"LocaleId\": locale_id,\n",
    "        \"LocaleName\": locale_name,\n",
    "        \"BusinessNeeds\": []\n",
    "    }\n",
    "\n",
    "    # Process each BusinessNeed\n",
    "    for business_need_id, business_need_name in business_need_mapping.items():\n",
    "        if pd.isna(business_need_id) or pd.isna(business_need_name):\n",
    "            continue  # Skip if either key or name is missing\n",
    "\n",
    "        business_need_entry = {\n",
    "            \"BusinessNeedId\": str(int(business_need_id)),\n",
    "            \"Benefit\": {\n",
    "                \"BenefitId\": \"\",\n",
    "                \"DisplayOrder\": \"\",\n",
    "                \"ReasonToBelieve\": \"\",\n",
    "                \"TechnicalProof\": \"\",\n",
    "                \"LegalNotice\": \"\",\n",
    "                \"ImageUrl\": \"\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Retrieve the BenefitId and other attributes based on column names with suffixes\n",
    "        benefit_name = row.get(f\"{business_need_name} Benefit in your country\", \"\")\n",
    "        if benefit_name in benefit_id_mapping:\n",
    "            benefit_id = benefit_id_mapping[benefit_name]\n",
    "            business_need_entry[\"Benefit\"][\"BenefitId\"] = benefit_id\n",
    "\n",
    "        # Define the column names with suffixes to get specific attributes\n",
    "        display_order_col = f\"{business_need_name} Sort order in your country (from 1 to 9)\"\n",
    "        reason_col = f\"{business_need_name} Reason to believe in your language\"\n",
    "        proof_col = f\"{business_need_name} Technical proof in your language\"\n",
    "        legal_notice_col = f\"{business_need_name} Legal notice in your language\"\n",
    "        \n",
    "        # Retrieve each attribute for the business need\n",
    "        business_need_entry[\"Benefit\"][\"DisplayOrder\"] = row.get(display_order_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"ReasonToBelieve\"] = row.get(reason_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"TechnicalProof\"] = row.get(proof_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"LegalNotice\"] = row.get(legal_notice_col, \"\")\n",
    "\n",
    "        # Append the business need entry to the target market model\n",
    "        target_market_model[\"BusinessNeeds\"].append(business_need_entry)\n",
    "\n",
    "    # Update or add the specified market model in the segmentation JSON without removing other locales\n",
    "    found_market_model = False\n",
    "    for market_model in segmentation_json.get(\"MarketModels\", []):\n",
    "        if market_model[\"LocaleId\"] == locale_id:\n",
    "            market_model.update(target_market_model)\n",
    "            found_market_model = True\n",
    "            break\n",
    "\n",
    "    if not found_market_model:\n",
    "        segmentation_json.setdefault(\"MarketModels\", []).append(target_market_model)\n",
    "\n",
    "    # Convert updated JSON to string and prepare for Excel output with \"ProductSegmentationJson\" as the column name\n",
    "    segmentation_json_str = json.dumps(segmentation_json, ensure_ascii=False)\n",
    "    excel_data.append({\n",
    "        \"ProductSegmentationJson\": segmentation_json_str,\n",
    "        \"sys_id\": product_entity_sys_id,\n",
    "        \"ProductGlobalId\": product_global_id\n",
    "    })\n",
    "\n",
    "# Write updated data to Excel\n",
    "df_output = pd.DataFrame(excel_data)\n",
    "output_excel_path = \"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\Segmentation_Output_006.xlsx\"\n",
    "df_output.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"The Excel file with JSON segmentation data has been successfully created and saved as {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c517a2-ed7c-4a54-bddf-e1364d78ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple products with benefit key added\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the data with MultiIndex headers\n",
    "# tld_data est chargé avec deux en-têtes pour capturer les noms de colonne dans deux lignes (niveau 0 et niveau 1).\n",
    "tld_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\filtered_Tld_B2B_1.xlsx\", header=[0, 1])\n",
    "\n",
    "# Flatten the MultiIndex headers into single-level by joining header levels with a space\n",
    "# tld_data.columns refers to the column headers of the DataFrame tld_data.\n",
    "#.values extracts these column names as an array of tuples, allowing them to be accessed directly.\n",
    "#Using ' '.join(col) means joining the two header levels with a space (' '), so a tuple like ('Product ID', 'Global') becomes 'Product ID Global'.\n",
    "# La méthode strip() supprime les espaces en début et en fin de chaîne dans le résultat final. Cela est utile si des espaces supplémentaires ont été ajoutés lors de la combinaison (join) des éléments.\n",
    "tld_data.columns = [' '.join(col).strip() for col in tld_data.columns.values]\n",
    "\n",
    "# Print flattened columns for verification\n",
    "print(\"Flattened columns with both headers:\", tld_data.columns)\n",
    "\n",
    "# Load the CVL file and create mappings for Business Needs and Benefits\n",
    "cvl_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\CVL_B2B Benefit and Business Key.xlsx\")\n",
    "#  La fonction dropna() de Pandas supprime les lignes avec des valeurs manquantes (NaN) dans un DataFrame.\n",
    "cvl_data_cleaned = cvl_data.dropna(subset=['BusinessNeed_Key', 'Benefits_Key'])\n",
    "# Create mappings from cleaned CVL data\n",
    "business_need_mapping = cvl_data_cleaned.set_index('BusinessNeed_Key')['Business Need'].to_dict()  # Maps BusinessNeed_Key to Business Need\n",
    "benefit_id_mapping = cvl_data_cleaned.set_index('Benefit in your country')['Benefits_Key'].to_dict()  # Maps Benefit in your country to Benefits_Key\n",
    "\n",
    "# Initialize a list to store each product's data\n",
    "products_data = []\n",
    "\n",
    "# Process each product row in the TLD data\n",
    "# Cette boucle for parcourt chaque ligne (ou produit) du DataFrame tld_data.\n",
    "for _, row in tld_data.iterrows():\n",
    "    # Retrieve ProductGlobalID and sys_id using flattened names\n",
    "    product_global_id = row.get(\"Unnamed: 1_level_0 ProductGlobalID\", \"\").strip()\n",
    "    product_entity_sys_id = str(row.get(\"Unnamed: 0_level_0 sys_id\", \"\")).strip()\n",
    "    \n",
    "    # Ensure both identifiers are present\n",
    "    if not product_global_id or not product_entity_sys_id:\n",
    "        print(f\"Skipping row due to missing ProductGlobalID or sys_id: {row}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize product structure\n",
    "    product_data = {\n",
    "        \"ProductGlobalId\": product_global_id,\n",
    "        \"ProductEntitySysId\": product_entity_sys_id,\n",
    "        \"MarketModels\": [\n",
    "            {\n",
    "                \"LocaleId\": \"fr-FR\",\n",
    "                \"LocaleName\": \"French (France)\",\n",
    "                \"BusinessNeeds\": []\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Process each BusinessNeed\n",
    "    # business_need_mapping.items() : La méthode .items() retourne les paires clé-valeur sous forme de tuples du mapping  (clé, valeur).\n",
    "  \n",
    "    for business_need_id, business_need_name in business_need_mapping.items():\n",
    "          # Crée un dictionnaire business_need_entry qui représente la structure de chaque besoin métier (BusinessNeed)\n",
    "        # à ajouter dans le fichier JSON parce que le json prends un entier .\n",
    "        business_need_entry = {\n",
    "            \"BusinessNeedId\": str(int(business_need_id)),\n",
    "            \"Benefit\": {\n",
    "                \"BenefitId\": \"\",\n",
    "                \"DisplayOrder\": \"\",\n",
    "                \"ReasonToBelieve\": \"\",\n",
    "                \"TechnicalProof\": \"\",\n",
    "                \"LegalNotice\": \"\",\n",
    "                \"ImageUrl\": \"\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Retrieve the BenefitId and other attributes based on column names with suffixes\n",
    "        benefit_name = row.get(f\"{business_need_name} Benefit in your country\", \"\")\n",
    "        if benefit_name in benefit_id_mapping:\n",
    "            benefit_id = benefit_id_mapping[benefit_name]\n",
    "            business_need_entry[\"Benefit\"][\"BenefitId\"] = benefit_id\n",
    "\n",
    "        # Define the column names with suffixes to get specific attributes\n",
    "        display_order_col = f\"{business_need_name} Sort order in your country (from 1 to 9)\"\n",
    "        reason_col = f\"{business_need_name} Reason to believe in your language\"\n",
    "        proof_col = f\"{business_need_name} Technical proof in your language\"\n",
    "        legal_notice_col = f\"{business_need_name} Legal notice in your language\"\n",
    "        \n",
    "        # Retrieve each attribute for the business need\n",
    "        # La méthode row.get() va chercher dans la ligne (row) une colonne \n",
    "        # qui correspond au nom de colonne exact, construit dynamiquement comme ceci : {business_need_name} Sort order in your country (from 1 to 9).\n",
    "        business_need_entry[\"Benefit\"][\"DisplayOrder\"] = row.get(display_order_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"ReasonToBelieve\"] = row.get(reason_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"TechnicalProof\"] = row.get(proof_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"LegalNotice\"] = row.get(legal_notice_col, \"\")\n",
    "\n",
    "        # Append the business need to the product's MarketModels\n",
    "        # adding a detailed business need entry (business_need_entry) to the \"BusinessNeeds\" \n",
    "        # list within the first market model (\"fr-FR\") of the product data, ensuring that all \n",
    "        # relevant information for that business need is included in the product’s JSON structure.\n",
    "        product_data[\"MarketModels\"][0][\"BusinessNeeds\"].append(business_need_entry)\n",
    "\n",
    "    # Append the complete product data to the products list\n",
    "    products_data.append(product_data)\n",
    "\n",
    "# Save the updated JSON with multiple products\n",
    " # sauvegarde les données des produits en format JSON lisible  dans le fichier Updated_B2B_multiple_products_1.json.\n",
    "output_file = \"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\Updated_B2B_multiple_products_1.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(products_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"The JSON file with multiple products has been successfully created and saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f36cb55-57b6-4226-81e1-ef8bcb6e9baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier JSON avec plusieurs produits pour Arabic (Saudi Arabia) a été créé et sauvegardé avec succès sous C:\\Users\\E106467\\Documents\\Json Mathilde\\Updated_B2B_multiple_products_ar-SA.json\n"
     ]
    }
   ],
   "source": [
    "# if we want to change the local id and name for different countries \n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Définir les valeurs de localisation dynamiques\n",
    "locale_id = \"ar-SA\"\n",
    "locale_name = \"Arabic (Saudi Arabia)\"\n",
    "\n",
    "# Charger les données avec les en-têtes multi-niveaux\n",
    "tld_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\filtered_Tld_B2B_1.xlsx\", header=[0, 1])\n",
    "tld_data.columns = [' '.join(col).strip() for col in tld_data.columns.values]\n",
    "\n",
    "# Charger le fichier CVL et créer les mappings pour les Business Needs et les Benefits\n",
    "cvl_data = pd.read_excel(\"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\CVL_B2B Benefit and Business Key.xlsx\")\n",
    "cvl_data_cleaned = cvl_data.dropna(subset=['BusinessNeed_Key', 'Benefits_Key'])\n",
    "business_need_mapping = cvl_data_cleaned.set_index('BusinessNeed_Key')['Business Need'].to_dict()\n",
    "benefit_id_mapping = cvl_data_cleaned.set_index('Benefit in your country')['Benefits_Key'].to_dict()\n",
    "\n",
    "# Initialiser une liste pour stocker les données de chaque produit\n",
    "products_data = []\n",
    "\n",
    "# Traiter chaque ligne de produit dans les données TLD\n",
    "for _, row in tld_data.iterrows():\n",
    "    product_global_id = row.get(\"Unnamed: 1_level_0 ProductGlobalID\", \"\").strip()\n",
    "    product_entity_sys_id = str(row.get(\"Unnamed: 0_level_0 sys_id\", \"\")).strip()\n",
    "\n",
    "    if not product_global_id or not product_entity_sys_id:\n",
    "        print(f\"Skipping row due to missing ProductGlobalID or sys_id: {row}\")\n",
    "        continue\n",
    "\n",
    "    # Créer la structure de données du produit avec les valeurs de localisation\n",
    "    product_data = {\n",
    "        \"ProductGlobalId\": product_global_id,\n",
    "        \"ProductEntitySysId\": product_entity_sys_id,\n",
    "        \"MarketModels\": [\n",
    "            {\n",
    "                \"LocaleId\": locale_id,\n",
    "                \"LocaleName\": locale_name,\n",
    "                \"BusinessNeeds\": []\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Traiter chaque BusinessNeed\n",
    "    for business_need_id, business_need_name in business_need_mapping.items():\n",
    "        business_need_entry = {\n",
    "            \"BusinessNeedId\": str(int(business_need_id)),\n",
    "            \"Benefit\": {\n",
    "                \"BenefitId\": \"\",\n",
    "                \"DisplayOrder\": \"\",\n",
    "                \"ReasonToBelieve\": \"\",\n",
    "                \"TechnicalProof\": \"\",\n",
    "                \"LegalNotice\": \"\",\n",
    "                \"ImageUrl\": \"\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Récupérer l'ID de bénéfice et les autres attributs\n",
    "        benefit_name = row.get(f\"{business_need_name} Benefit in your country\", \"\")\n",
    "        if benefit_name in benefit_id_mapping:\n",
    "            benefit_id = benefit_id_mapping[benefit_name]\n",
    "            business_need_entry[\"Benefit\"][\"BenefitId\"] = benefit_id\n",
    "\n",
    "        display_order_col = f\"{business_need_name} Sort order in your country (from 1 to 9)\"\n",
    "        reason_col = f\"{business_need_name} Reason to believe in your language\"\n",
    "        proof_col = f\"{business_need_name} Technical proof in your language\"\n",
    "        legal_notice_col = f\"{business_need_name} Legal notice in your language\"\n",
    "\n",
    "        business_need_entry[\"Benefit\"][\"DisplayOrder\"] = row.get(display_order_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"ReasonToBelieve\"] = row.get(reason_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"TechnicalProof\"] = row.get(proof_col, \"\")\n",
    "        business_need_entry[\"Benefit\"][\"LegalNotice\"] = row.get(legal_notice_col, \"\")\n",
    "\n",
    "        # Ajouter le besoin à la liste BusinessNeeds\n",
    "        product_data[\"MarketModels\"][0][\"BusinessNeeds\"].append(business_need_entry)\n",
    "\n",
    "    # Ajouter le produit terminé à la liste principale des produits\n",
    "    products_data.append(product_data)\n",
    "\n",
    "# Enregistrer le fichier JSON avec les produits multiples\n",
    "output_file = \"C:\\\\Users\\\\E106467\\\\Documents\\\\Json Mathilde\\\\Updated_B2B_multiple_products_ar-SA.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(products_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Le fichier JSON avec plusieurs produits pour {locale_name} a été créé et sauvegardé avec succès sous {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01affb29-6400-47d5-99b5-b611b2afc1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
